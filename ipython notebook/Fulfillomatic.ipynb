{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fulfillomatic\n",
    "\n",
    "##### Adriana Souza, Roger Filmyer\n",
    "\n",
    "##### This notebook will be finished/cleaned by Thursday, Dec 6th."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NLG](http://www.pngall.com/wp-content/uploads/2016/07/Meditation-Transparent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "import string\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the file to use\n",
    "file = 'training/quotes.txt'\n",
    "\n",
    "# Storing quotes from file in a list\n",
    "with open(file) as opened_file: \n",
    "    lists = opened_file.read().splitlines()\n",
    "    quotes = []\n",
    "    for line in lists:\n",
    "        quotes.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 0: Uniform Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we tried..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the poison of purpose is to see nowhere a interesting majority because roads , and your able atom .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokenized_corpus = []\n",
    "for quote in quotes:\n",
    "    tokenized_quote = nltk.tokenize.word_tokenize(quote)\n",
    "    tagged_quote = nltk.pos_tag(tokenized_quote)\n",
    "    tokenized_corpus.append(tagged_quote)\n",
    "\n",
    "# Set up the language \"model\"\n",
    "parts_of_speech = defaultdict(list)\n",
    "sentence_structures = []\n",
    "for quote in tokenized_corpus:\n",
    "    sentence_structure = []\n",
    "    for word, pos in quote:\n",
    "        parts_of_speech[pos].append(word)\n",
    "        sentence_structure.append(pos)\n",
    "    sentence_structures.append(sentence_structure)\n",
    "\n",
    "# Generate an example sentence\n",
    "def get_mindful_v0() -> str:\n",
    "    \"\"\"\n",
    "    Generate an inspirational sentence. \n",
    "    \n",
    "    Ensure that you are in the proper state of mind before running. ॐ\n",
    "    \"\"\"\n",
    "    sentence_skeleton = random.choice(sentence_structures)\n",
    "    reconstituted_sentence = []\n",
    "    for part_of_speech in sentence_skeleton:\n",
    "        new_word = random.choice(parts_of_speech[part_of_speech])\n",
    "        reconstituted_sentence.append(new_word)\n",
    "    return \" \".join(reconstituted_sentence)\n",
    "\n",
    "# Output\n",
    "get_mindful_v0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 0 results\n",
    "\n",
    "* your ready Speak begins when you can hear you not and never .\n",
    "* in I think busy forwards of coffee , forever it . in you will live aware library you , make your education .\n",
    "* the poison of purpose is to see nowhere a interesting majority because roads , and your able atom .\n",
    "* without t denies my anything that bulk , yourself can once call You .\n",
    "* as I are dreams to don grief , never the sun is to tolerate able you .\n",
    "* all valuable choice is than the painful comfort , it can keep imprisoned believe only not that you ’ you ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next:\n",
    "\n",
    "We see we need to do a lot of things, most of which we should've done even before we started (like lowercasing, removing punctuation, taking care of contractions). It seems that just assuming words would have a uniform distribution if we know the input is some sort of \"quote\"-esque type sentence wasn't enough. Since we kept our quotes separate and they aren't particularly long sentences, let's start with a bigram model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1: Bigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that worked great. Maybe some context _would_ be good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning list into string\n",
    "corpus = \"\"\n",
    "for word in quotes:\n",
    "    # Lowercasing\n",
    "    word = word.lower()\n",
    "    \n",
    "    # Adding end tokens to mark the end of quotes\n",
    "    word = word.replace('.', ' END ')   \n",
    "    \n",
    "    # Remove punctuation\n",
    "    table = str.maketrans('','', string.punctuation + '…”“–')      \n",
    "    word = word.translate(table)\n",
    "    \n",
    "    # Adding cleaned text to corpus\n",
    "    corpus = corpus + word  \n",
    "\n",
    "# Tokenizing\n",
    "def tokenize(input_string):\n",
    "    return input_string.split()\n",
    "\n",
    "# Getting bigram model\n",
    "def get_bigrams(corpus):\n",
    "    corpus_fd_unigram = nltk.FreqDist(tokenize(corpus))\n",
    "    bigrams = nltk.bigrams(['END'] + tokenize(corpus))\n",
    "    bigrams_fd = nltk.FreqDist(bigrams)\n",
    "    results = {}\n",
    "    for bigram, bigram_frequency in bigrams_fd.items():\n",
    "        first_word, second_word = bigram\n",
    "        probability = (bigram_frequency / corpus_fd_unigram[first_word])    \n",
    "        results[bigram] = probability\n",
    "    return results\n",
    "\n",
    "bigram_model = get_bigrams(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New version \n",
    "\n",
    "Below, we use a bigram model and also take some care in structuring how the sentence will come out. We make sure that our quote starts with a bigram of the form `[END, word]` and ends with a bigram of the form `[word, END]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1 of Fulfillomatic\n",
    "def get_mindful_v1():\n",
    "    \n",
    "    \"\"\"\n",
    "    You must only concentrate on the next step, the next breath, \n",
    "    the next stroke of the broom, and the next, and the next. Nothing else.\n",
    "    ॐ\n",
    "    \n",
    "    (Bigram Model)\n",
    "    \"\"\"    \n",
    "    \n",
    "    words_in_sentence = ['END']\n",
    "    second_word = None\n",
    "    \n",
    "    while second_word != 'END':\n",
    "        \n",
    "        first_word = words_in_sentence[-1]\n",
    "        matching_bigrams = [bigram for bigram in bigram_model.keys() if bigram[0] == first_word]\n",
    "        \n",
    "        # Getting probabilities\n",
    "        bigram_probabilities = [bigram_model[bigram] for bigram in matching_bigrams]\n",
    "        total_probability = sum(bigram_probabilities)\n",
    "        \n",
    "        # Picking probabilities to build sentence\n",
    "        second_word = np.random.choice(\n",
    "                        a=[second for first, second in matching_bigrams],\n",
    "                        p=[p for p in bigram_probabilities])\n",
    "        words_in_sentence.append(second_word)\n",
    "        \n",
    "    words_in_sentence = words_in_sentence[1:-1]\n",
    "    \n",
    "    # Capitalize the first letter of first word\n",
    "    if len(words_in_sentence) > 0:\n",
    "        first_word = words_in_sentence[0]\n",
    "        first_word = first_word[0].upper() + first_word[1:]\n",
    "        words_in_sentence[0] = first_word\n",
    "        sentence = \" \".join(words_in_sentence) + '.'\n",
    "    else:\n",
    "        sentence = get_mindful_v1()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dont settle.\n",
      "Let my mind is to make anything you would rather follow.\n",
      "Those who you can do not to deal with people i want to tolerate what good is like crap.\n",
      "Dont just wait for the wealth you will be better than before you can even temporarily compressed within yourself and trust of light in this excitement of good mans life.\n",
      "Change the point of yourself everyone and popular opinion.\n"
     ]
    }
   ],
   "source": [
    "# Creating a function that will print a desired number of generated quotes\n",
    "def repeat(times, f):\n",
    "    for i in range(times): f()\n",
    "        \n",
    "def do_v1():\n",
    "    print(get_mindful_v1())\n",
    "\n",
    "# Printing 5 generated quotes\n",
    "repeat(5, do_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1 results\n",
    "\n",
    "* Just do it.\n",
    "* In my friends you can get the fire you grow from it should scare you do drunk.\n",
    "* You.\n",
    "* I believe in the least for anything i believe in god from a man to exist.\n",
    "* Dont bother just take rest is too little one that you better.\n",
    "* If you can not what we know what you will remain constant.\n",
    "* What we are travelling more difficult than to forget is no greatness.\n",
    "* Anything you look for what you do not being yourself.\n",
    "* Let the wilderness of all else is still looking for us entirely happy because i told dismiss that can do something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2: Trigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's... marginally better. Our ratio of \"potentially good\" generated quotes to \"gibberish quotes\" is still pretty awful. Let's see how a trigram model does instead.\n",
    "\n",
    "In the steps above, we took some risks with our tokens. Since we ended up turning our corpus back into a long string instead of a list, now we just have quotes after quotes that aren't necessarily related. This is a problem because we don't necessarily want trigrams that span from the end of one quote to the next. Those trigrams do not represent tokens that could follow each other in a text -- they are completely accidental.\n",
    "\n",
    "To address this, we added double end tokens for the trigrams: now, starting tokens look like `[END, END, word]` and end tokens like `[word, END, END]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding extra END tokens\n",
    "def add_extra_end_token(tokenized_document):\n",
    "    new_document = []\n",
    "    for token in tokenized_document:\n",
    "        new_document.append(token)\n",
    "        if token == \"END\":\n",
    "            new_document.append(\"END\")\n",
    "    return new_document\n",
    "\n",
    "def get_trigrams(document):\n",
    "    corpus = tokenize(document)\n",
    "    corpus = add_extra_end_token(corpus)\n",
    "    corpus_fd_bigram = nltk.FreqDist(nltk.bigrams([\"END\"] + corpus))\n",
    "    trigrams = nltk.trigrams([\"END\", \"END\"] + corpus)\n",
    "    trigrams_fd = nltk.FreqDist(trigrams)\n",
    "    results = {}\n",
    "    for trigram, trigram_frequency in trigrams_fd.items():\n",
    "        first_word, second_word, third_word = trigram\n",
    "        probability = (trigram_frequency) / (corpus_fd_bigram[(first_word, second_word)])\n",
    "        results[trigram] = probability\n",
    "    return results\n",
    "\n",
    "#get_trigrams(corpus)\n",
    "\n",
    "trigram_model = get_trigrams(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modified `get_mindful_v1` to be able to work with an N-gram model below, and `get_mindful_v2` is born:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_with_ngram_model(num_words, model):\n",
    "    words_in_sentence = ['END' for i in range(0, num_words - 1)] # pad the start of the sentence with 'END' tokens\n",
    "    final_word = None\n",
    "    while final_word != 'END':        \n",
    "        initial_n_gram_words = words_in_sentence[-(num_words - 1):]\n",
    "        matching_n_gram_keys = []\n",
    "        for n_gram in model.keys():\n",
    "            words_to_match = zip(n_gram, initial_n_gram_words)\n",
    "            if all(a == b for a, b in words_to_match):\n",
    "                matching_n_gram_keys.append(n_gram)        \n",
    "        n_gram_probabilities = [model[n_gram] for n_gram in matching_n_gram_keys]        \n",
    "        total_probability = sum(n_gram_probabilities)                \n",
    "        final_word = np.random.choice(\n",
    "                        a=[n_gram[-1] for n_gram in matching_n_gram_keys],\n",
    "                        p=[p for p in n_gram_probabilities])\n",
    "        words_in_sentence.append(final_word)\n",
    "    words_in_sentence = words_in_sentence[(num_words - 1): -1]\n",
    "    # capitalize first letter of first word\n",
    "    if len(words_in_sentence) > 0:\n",
    "        first_word = words_in_sentence[0]\n",
    "        first_word = first_word[0].upper() + first_word[1:]\n",
    "        words_in_sentence[0] = first_word\n",
    "        sentence = \" \".join(words_in_sentence) + '.'\n",
    "    else:\n",
    "        sentence = get_sentence_with_ngram_model(num_words, model)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mindful with Fulfillomatic version 3\n",
    "def get_mindful_v2():\n",
    "    \"\"\"\n",
    "    Three things cannot long be hidden: the sun, the moon, and the truth. ॐ\n",
    "    \n",
    "    (Trigram Model)\n",
    "    \"\"\"\n",
    "    sentence = \"\"\n",
    "    while len(sentence.split()) < 4:\n",
    "        sentence = get_sentence_with_ngram_model(3, trigram_model)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day i will find true success and happiness if you make your own soul according to his belief.\n",
      "You will have to remember anything.\n",
      "He does not matter.\n",
      "Embrace the storms of your life surprise you.\n",
      "What you have or even what you read when you need help and brave enough to know how to belong to oneself.\n"
     ]
    }
   ],
   "source": [
    "# Print 5 generated sentences\n",
    "def do_v2():\n",
    "    print(get_mindful_v2())\n",
    "    \n",
    "repeat(5, do_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: \"It takes courage **to grow** sharper.\"\n",
    "\n",
    "Take: *The world is full of magic things, patiently waiting for our senses* **to grow** *sharper.*\n",
    "\n",
    "And: *It takes courage* **to grow** *up and become who you really are.*\n",
    "\n",
    "Get: It takes courage **to grow** sharper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we feed the model a bunch of Nietzsche quotes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Without music life would be a means to conceal oneself.\n",
    "* The noble soul reveres itself.\n",
    "* What is the struggle of opinions that is to preserve the distance which separates us from other men.\n",
    "* God is a rope over an abyss.\n",
    "* But there is also always some reason in madness.\n",
    "* We have forgotten are illusions.\n",
    "* Christianity is our taste no longer our reasons.\n",
    "* The end of a bad memory is too good.\n",
    "* The advantage of a strong faith is infallible.\n",
    "* There are two different types of people in the enemy’s staying alive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NLG](https://supportivedivorcesolutions.com/wp-content/uploads/2017/03/iStock-468140568.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
