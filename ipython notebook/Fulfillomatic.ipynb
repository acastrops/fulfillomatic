{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fulfillomatic\n",
    "\n",
    "##### Adriana Souza, Roger Filmyer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NLG](http://www.pngall.com/wp-content/uploads/2016/07/Meditation-Transparent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "import string\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the file to use\n",
    "#file = 'training/inspirational_quotes.txt'\n",
    "#file = 'training/nietzsche_quotes.txt'\n",
    "file = 'training/zen_quotes.txt'\n",
    "#file = 'training/everything.txt'  # Worse quote results due to different styles being mixed together.\n",
    "\n",
    "# Storing quotes from file in a list\n",
    "with open(file, encoding='utf-8') as opened_file: \n",
    "    lists = opened_file.read().splitlines()\n",
    "    quotes = []\n",
    "    for line in lists:\n",
    "        quotes.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 0: Unweighted Parts-of-Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we tried..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "tokenized_corpus = []\n",
    "for quote in quotes:\n",
    "    tokenized_quote = nltk.tokenize.word_tokenize(quote)\n",
    "    tagged_quote = nltk.pos_tag(tokenized_quote)\n",
    "    tokenized_corpus.append(tagged_quote)\n",
    "\n",
    "# Set up the language \"model\"\n",
    "parts_of_speech = defaultdict(list)\n",
    "sentence_structures = []\n",
    "for quote in tokenized_corpus:\n",
    "    sentence_structure = []\n",
    "    for word, pos in quote:\n",
    "        parts_of_speech[pos].append(word)\n",
    "        sentence_structure.append(pos)\n",
    "    sentence_structures.append(sentence_structure)\n",
    "\n",
    "# Generate an example sentence\n",
    "# get_mindful_v0()\n",
    "def chaos():\n",
    "    \"\"\"\n",
    "    Generate an inspirational sentence. \n",
    "    \n",
    "    Ensure that you are in the proper state of mind before running. ॐ\n",
    "    \"\"\"\n",
    "    sentence_skeleton = random.choice(sentence_structures)\n",
    "    reconstituted_sentence = []\n",
    "    for part_of_speech in sentence_skeleton:\n",
    "        new_word = random.choice(parts_of_speech[part_of_speech])\n",
    "        reconstituted_sentence.append(new_word)\n",
    "    return \" \".join(reconstituted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zen between goal ?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output\n",
    "chaos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 0 -- Chaos -- results\n",
    "\n",
    "* your ready Speak begins when you can hear you not and never .\n",
    "* in I think busy forwards of coffee , forever it . in you will live aware library you , make your education .\n",
    "* the poison of purpose is to see nowhere a interesting majority because roads , and your able atom .\n",
    "* without t denies my anything that bulk , yourself can once call You .\n",
    "* as I are dreams to don grief , never the sun is to tolerate able you .\n",
    "* all valuable choice is than the painful comfort , it can keep imprisoned believe only not that you ’ you ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next:\n",
    "\n",
    "We see we need to do a lot of things, most of which we should've done even before we started (like lowercasing, removing punctuation, taking care of contractions). It seems that just assuming words would have a uniform distribution if we know the input is some sort of \"quote\"-esque type sentence wasn't enough. Since we kept our quotes separate and they aren't particularly long sentences, let's start with a bigram model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1: Bigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that worked great. Maybe some context _would_ be good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning list into string\n",
    "corpus = \"\"\n",
    "for word in quotes:\n",
    "    # Lowercasing\n",
    "    word = word.lower()\n",
    "    \n",
    "    # Adding end tokens to mark the end of quotes\n",
    "    word = word.replace('.', ' END ')   \n",
    "    \n",
    "    # Remove punctuation\n",
    "    table = str.maketrans('','', string.punctuation + '…”“–')      \n",
    "    word = word.translate(table)\n",
    "    \n",
    "    # Adding cleaned text to corpus\n",
    "    corpus = corpus + word  \n",
    "\n",
    "# Tokenizing\n",
    "def tokenize(input_string):\n",
    "    return input_string.split()\n",
    "\n",
    "# Getting bigram model\n",
    "def get_bigrams(corpus):\n",
    "    corpus_fd_unigram = nltk.FreqDist(tokenize(corpus))\n",
    "    bigrams = nltk.bigrams(['END'] + tokenize(corpus))\n",
    "    bigrams_fd = nltk.FreqDist(bigrams)\n",
    "    results = {}\n",
    "    for bigram, bigram_frequency in bigrams_fd.items():\n",
    "        first_word, second_word = bigram\n",
    "        probability = (bigram_frequency / corpus_fd_unigram[first_word])    \n",
    "        results[bigram] = probability\n",
    "    return results\n",
    "\n",
    "bigram_model = get_bigrams(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New version \n",
    "\n",
    "Below, we use a bigram model and also take some care in structuring how the sentence will come out. We make sure that our quote starts with a bigram of the form `[END, word]` and ends with a bigram of the form `[word, END]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to get an n-gram model\n",
    "def get_sentence_with_ngram_model(num_words, model):\n",
    "    words_in_sentence = ['END' for i in range(0, num_words - 1)] # Pad the start of the sentence with 'END' tokens\n",
    "    final_word = None\n",
    "    \n",
    "    while final_word != 'END':        \n",
    "        initial_n_gram_words = words_in_sentence[-(num_words - 1):]\n",
    "        matching_n_gram_keys = []\n",
    "        \n",
    "        #Get probabilites\n",
    "        for n_gram in model.keys():\n",
    "            words_to_match = zip(n_gram, initial_n_gram_words)\n",
    "            if all(a == b for a, b in words_to_match):\n",
    "                matching_n_gram_keys.append(n_gram) \n",
    "                \n",
    "        # Pick probabilities        \n",
    "        n_gram_probabilities = [model[n_gram] for n_gram in matching_n_gram_keys]        \n",
    "        total_probability = sum(n_gram_probabilities)                \n",
    "        final_word = np.random.choice(\n",
    "                        a=[n_gram[-1] for n_gram in matching_n_gram_keys],\n",
    "                        p=[p for p in n_gram_probabilities])\n",
    "        words_in_sentence.append(final_word)\n",
    "        \n",
    "    words_in_sentence = words_in_sentence[(num_words - 1): -1]\n",
    "    \n",
    "    # Capitalize first letter of first word\n",
    "    if len(words_in_sentence) > 0:\n",
    "        first_word = words_in_sentence[0]\n",
    "        first_word = first_word[0].upper() + first_word[1:]\n",
    "        words_in_sentence[0] = first_word\n",
    "        sentence = \" \".join(words_in_sentence) + '.'\n",
    "    else:\n",
    "        sentence = get_sentence_with_ngram_model(num_words, model)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with a bigram model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1 of Fulfillomatic\n",
    "def duality():    \n",
    "    \"\"\"\n",
    "    You must only concentrate on the next step, the next breath, \n",
    "    the next stroke of the broom, and the next, and the next. Nothing else.\n",
    "    ॐ\n",
    "    \n",
    "    (Bigram Model)\n",
    "    \"\"\"    \n",
    "    sentence = \"\"\n",
    "    while len(sentence.split()) < 4:\n",
    "        sentence = get_sentence_with_ngram_model(2, bigram_model)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life as long enough.\n",
      "Any concrete reality you eat.\n",
      "Time is happy just sit.\n",
      "Knowing nothing within our mind should not a man seeks is not judge you have many attachment you desired.\n",
      "This scripture throw it.\n"
     ]
    }
   ],
   "source": [
    "# Creating a function that will print a desired number of generated quotes\n",
    "def repeat(times, f):\n",
    "    for i in range(times): f()\n",
    "    \n",
    "def do_v1():\n",
    "    print(duality())\n",
    "\n",
    "# Printing 5 generated quotes\n",
    "repeat(5, do_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinging is the best one of intelligence .\n",
      "that Nobody of you look other , next cravings will go You .\n",
      "no nothing because the crazy dwell everyday , soft except the fishermen between the man , long to be , to go , or let to all the teaches .\n",
      "of yourself should see the your move ; distraction , glimpsing , trusting and coming down - mind to Do the first rules between its diminish anything , you will try few of not letting all death .\n",
      "There becomes eventually beautiful to happen . You not use to see the distinctions .\n"
     ]
    }
   ],
   "source": [
    "def do_v0():\n",
    "    print(chaos())\n",
    "\n",
    "# Printing 5 generated quotes\n",
    "repeat(5, do_v0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1 results\n",
    "\n",
    "* Just do it.\n",
    "* In my friends you can get the fire you grow from it should scare you do drunk.\n",
    "* You.\n",
    "* I believe in the least for anything i believe in god from a man to exist.\n",
    "* Dont bother just take rest is too little one that you better.\n",
    "* If you can not what we know what you will remain constant.\n",
    "* What we are travelling more difficult than to forget is no greatness.\n",
    "* Anything you look for what you do not being yourself.\n",
    "* Let the wilderness of all else is still looking for us entirely happy because i told dismiss that can do something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2: Trigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's... marginally better. Our ratio of \"potentially good\" generated quotes to \"gibberish quotes\" is still pretty awful. Let's see how a trigram model does instead.\n",
    "\n",
    "In the steps above, we took some risks with our tokens. Since we ended up turning our corpus back into a long string instead of a list, now we just have quotes after quotes that aren't necessarily related. This is a problem because we don't necessarily want trigrams that span from the end of one quote to the next. Those trigrams do not represent tokens that could follow each other in a text -- they are completely accidental.\n",
    "\n",
    "To address this, we added double end tokens for the trigrams: now, starting tokens look like `[END, END, word]` and end tokens like `[word, END, END]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding extra END tokens\n",
    "def add_extra_end_token(tokenized_document):\n",
    "    new_document = []\n",
    "    for token in tokenized_document:\n",
    "        new_document.append(token)\n",
    "        if token == \"END\":\n",
    "            new_document.append(\"END\")\n",
    "    return new_document\n",
    "\n",
    "def get_trigrams(document):\n",
    "    corpus = tokenize(document)\n",
    "    corpus = add_extra_end_token(corpus)\n",
    "    corpus_fd_bigram = nltk.FreqDist(nltk.bigrams([\"END\"] + corpus))\n",
    "    trigrams = nltk.trigrams([\"END\", \"END\"] + corpus)\n",
    "    trigrams_fd = nltk.FreqDist(trigrams)\n",
    "    results = {}\n",
    "    for trigram, trigram_frequency in trigrams_fd.items():\n",
    "        first_word, second_word, third_word = trigram\n",
    "        probability = (trigram_frequency) / (corpus_fd_bigram[(first_word, second_word)])\n",
    "        results[trigram] = probability\n",
    "    return results\n",
    "\n",
    "#get_trigrams(corpus)\n",
    "\n",
    "trigram_model = get_trigrams(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modified `get_mindful_v1` to be able to work with an N-gram model below, and `get_mindful_v2` is born:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mindful with Fulfillomatic version 3\n",
    "def open_your_third_eye():\n",
    "    \"\"\"\n",
    "    Three things cannot long be hidden: the sun, the moon, and the truth. ॐ\n",
    "    \n",
    "    (Trigram Model)\n",
    "    \"\"\"\n",
    "    sentence = \"\"\n",
    "    while len(sentence.split()) < 4:\n",
    "        sentence = get_sentence_with_ngram_model(3, trigram_model)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To see things for what they see not what they see not what they think the wise move through the world is first in ones own heart.\n",
      "The only zen you can understand the mind we can change our reality by changing our mind is utterly empty.\n",
      "A mind that prevents evil from arising in either.\n",
      "One must transcend techniques so that the young men of today are so contriving and so proud of their material possessions.\n",
      "If in our heart we still cling to anything do not exist for the sake of ourselves.\n",
      "If you chase two rabbits you catch none.\n",
      "Peace of mind rather than attacking the evil that is not crazy enough.\n",
      "That is within yourself rather than attacking the evil that is what it is about your own sense of confinement.\n",
      "An awakened person is someone who finds freedom in good fortune and fame.\n",
      "Zen is an idle person.\n",
      "Not thinking but not dreaming.\n",
      "A fool because he has something to show for it.\n",
      "That is not a raging waterfall.\n",
      "Our task must be deeply aware of the broom and the butterflies will come.\n",
      "It is only with total humility and in absolute stillness of mind that is what your life your tears will prevent you from seeing the stars.\n"
     ]
    }
   ],
   "source": [
    "# Print 5 generated sentences\n",
    "def do_v2():\n",
    "    print(open_your_third_eye())\n",
    "    \n",
    "repeat(15,do_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: \"It takes courage **to grow** sharper.\"\n",
    "\n",
    "Take: *\"The world is full of magic things, patiently waiting for our senses* **to grow** *sharper.\"*\n",
    "\n",
    "And: *\"It takes courage* **to grow** *up and become who you really are.\"*\n",
    "\n",
    "Get: It takes courage **to grow** sharper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we feed the model a bunch of Nietzsche quotes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Without music life would be a means to conceal oneself.\n",
    "* The noble soul reveres itself.\n",
    "* What is the struggle of opinions that is to preserve the distance which separates us from other men.\n",
    "* God is a rope over an abyss.\n",
    "* But there is also always some reason in madness.\n",
    "* We have forgotten are illusions.\n",
    "* Christianity is our taste no longer our reasons.\n",
    "* The end of a bad memory is too good.\n",
    "* The advantage of a strong faith is infallible.\n",
    "* There are two different types of people in the enemy’s staying alive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we feed the model a bunch of Zen quotes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from pickle import dump\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin now to be what you will be hereafter.\n",
      "We have to do the best we are capable of. This is our sacred human responsibility.\n",
      "You have as much laughter as you have faith.\n",
      "The brain is wider than the \n",
      "['begin', 'now', 'to', 'be', 'what', 'you', 'will', 'be', 'hereafter', 'we', 'have', 'to', 'do', 'the', 'best', 'we', 'are', 'capable', 'of', 'this', 'is', 'our', 'sacred', 'human', 'responsibility', 'you', 'have', 'as', 'much', 'laughter', 'as', 'you', 'have', 'faith', 'the', 'brain', 'is', 'wider', 'than', 'the', 'sky', 'two', 'roads', 'diverged', 'in', 'a', 'wood', 'and', 'i', 'took', 'the', 'one', 'less', 'traveled', 'by', 'and', 'that', 'has', 'made', 'all', 'the', 'difference', 'a', 'goal', 'should', 'scare', 'you', 'a', 'little', 'and', 'excite', 'you', 'a', 'lot', 'listen', 'smile', 'agree', 'and', 'then', 'do', 'whatever', 'the', 'fuck', 'you', 'were', 'doing', 'to', 'do', 'anyway', 'magic', 'is', 'believing', 'in', 'yourself', 'if', 'you', 'can', 'do', 'that', 'you', 'can', 'make', 'anything', 'happen', 'the', 'world', 'is', 'full', 'of', 'magic', 'things', 'patiently', 'waiting', 'for', 'our', 'senses', 'to', 'grow', 'sharper', 'it', 'is', 'not', 'in', 'the', 'stars', 'to', 'hold', 'our', 'destiny', 'but', 'in', 'ourselves', 'if', 'you', 'are', 'not', 'willing', 'to', 'risk', 'the', 'unusual', 'you', 'will', 'have', 'to', 'settle', 'for', 'the', 'ordinary', 'learn', 'to', 'say', 'no', 'to', 'the', 'good', 'so', 'you', 'can', 'say', 'yes', 'to', 'the', 'best', 'great', 'things', 'never', 'came', 'from', 'comfort', 'zones', 'i', 'have', 'the', 'choice', 'of', 'being', 'constantly', 'active', 'and', 'happy', 'or', 'introspectively', 'passive', 'and', 'sad', 'or', 'i', 'can', 'go', 'mad', 'by', 'ricocheting', 'in', 'between', 'when', 'you', 'have', 'confidence', 'you']\n",
      "Total Tokens: 14479\n",
      "Unique Tokens: 2319\n",
      "Total Sequences: 14428\n"
     ]
    }
   ],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # replace '--' with a space ' '\n",
    "    doc = doc.replace('--', ' ')\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "\n",
    "# load document\n",
    "in_filename = 'training/inspirational_quotes.txt'\n",
    "doc = load_doc(in_filename)\n",
    "print(doc[:200])\n",
    "\n",
    "# clean document\n",
    "tokens = clean_doc(doc)\n",
    "print(tokens[:200])\n",
    "print('Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % len(set(tokens)))\n",
    "\n",
    "# organize into sequences of tokens\n",
    "length = 50 + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "    # select sequence of tokens\n",
    "    seq = tokens[i-length:i]\n",
    "    # convert into a line\n",
    "    line = ' '.join(seq)\n",
    "    # store\n",
    "    sequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "\n",
    "# save sequences to file\n",
    "out_filename = 'inspirational_sequences.txt'\n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 50, 50)            115950    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2319)              234219    \n",
      "=================================================================\n",
      "Total params: 501,069\n",
      "Trainable params: 501,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "in_filename = 'inspirational_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)\n",
    "\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# separate into input and output\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14428/14428 [==============================] - 28s 2ms/step - loss: 6.4614 - acc: 0.0423\n",
      "Epoch 2/10\n",
      "14428/14428 [==============================] - 26s 2ms/step - loss: 6.0335 - acc: 0.0455\n",
      "Epoch 3/10\n",
      "14428/14428 [==============================] - 26s 2ms/step - loss: 5.9990 - acc: 0.0457\n",
      "Epoch 4/10\n",
      "14428/14428 [==============================] - 26s 2ms/step - loss: 5.8853 - acc: 0.0478\n",
      "Epoch 5/10\n",
      "14428/14428 [==============================] - 27s 2ms/step - loss: 5.7977 - acc: 0.0572\n",
      "Epoch 6/10\n",
      "14428/14428 [==============================] - 27s 2ms/step - loss: 5.6890 - acc: 0.0570\n",
      "Epoch 7/10\n",
      "14428/14428 [==============================] - 26s 2ms/step - loss: 5.5990 - acc: 0.0665\n",
      "Epoch 8/10\n",
      "14428/14428 [==============================] - 27s 2ms/step - loss: 5.5218 - acc: 0.0731\n",
      "Epoch 9/10\n",
      "14428/14428 [==============================] - 26s 2ms/step - loss: 5.4530 - acc: 0.0755\n",
      "Epoch 10/10\n",
      "14428/14428 [==============================] - 26s 2ms/step - loss: 5.3899 - acc: 0.0792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f63117048>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# reload(keras.models)\n",
    "\n",
    "# save the model to file\n",
    "model.save('model.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failure nothing really worth having comes quickly and easily if it did i doubt that we would ever grow problems are only opportunities in work clothes wishes are like seeds few ever develop into something nothing can withstand the power of the human will if it is willing to stake its\n",
      "\n",
      "failure nothing really worth having comes quickly and easily if it did i doubt that we would ever grow problems are only opportunities in work clothes wishes are like seeds few ever develop into something nothing can withstand the power of the human will if it is willing to stake its\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load cleaned text sequences\n",
    "in_filename = 'inspirational_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "\n",
    "seq_length = len(lines[0].split()) - 1\n",
    "\n",
    "# load the model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    "\n",
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "encoded = tokenizer.texts_to_sequences([seed_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  47,  144,  257,  235,  486,  924,    6, 1812,   22,    9,  664,\n",
       "          17,  274,   12,   21,  152,  126,  138, 1813,   16,   33,  642,\n",
       "          11,   91, 1814,  484,   16,   68,  674,  353,  126,  464,  147,\n",
       "          93,   47,   15, 1815,    1,  163,    7,    1,  165,   10,   22,\n",
       "           9,    4,  176,    3, 1816,   98]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(encoded)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities for each word\n",
    "yhat = model.predict_classes(np.array(encoded)[:, 1:], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_word = ''\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index == yhat:\n",
    "        out_word = word\n",
    "        break\n",
    "        \n",
    "encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be the life of the most life and the world of the most life and the world of the most life and the world of the most life and the\n"
     ]
    }
   ],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "                # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 30)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NLG](https://supportivedivorcesolutions.com/wp-content/uploads/2017/03/iStock-468140568.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
